{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"stacked_AutoEncoders.ipynb","provenance":[{"file_id":"1KYKvdVQ_r32eT7o-_QqOcD_XtCc92F1t","timestamp":1629780313415},{"file_id":"1TBJsYNflgFHbS2M53gZngpTVKtvnLSDc","timestamp":1591633331181}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"K4f4JG1gdKqj"},"source":["#AutoEncoders"]},{"cell_type":"markdown","metadata":{"id":"1jbiqOK7dLGG"},"source":["##Downloading the dataset"]},{"cell_type":"markdown","metadata":{"id":"XL5MEkLcfRD2"},"source":["###ML-100K"]},{"cell_type":"code","metadata":{"id":"rjOPzue7FCXJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630162107829,"user_tz":-300,"elapsed":1145,"user":{"displayName":"CALEB KWASI DARKO","photoUrl":"","userId":"02161131878812025596"}},"outputId":"a58942be-65af-4660-a30f-f0886d7f4905"},"source":["!wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n","!unzip ml-100k.zip\n","!ls"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2021-08-28 14:48:26--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n","Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n","Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4924029 (4.7M) [application/zip]\n","Saving to: ‘ml-100k.zip’\n","\n","ml-100k.zip         100%[===================>]   4.70M  27.8MB/s    in 0.2s    \n","\n","2021-08-28 14:48:26 (27.8 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n","\n","Archive:  ml-100k.zip\n","   creating: ml-100k/\n","  inflating: ml-100k/allbut.pl       \n","  inflating: ml-100k/mku.sh          \n","  inflating: ml-100k/README          \n","  inflating: ml-100k/u.data          \n","  inflating: ml-100k/u.genre         \n","  inflating: ml-100k/u.info          \n","  inflating: ml-100k/u.item          \n","  inflating: ml-100k/u.occupation    \n","  inflating: ml-100k/u.user          \n","  inflating: ml-100k/u1.base         \n","  inflating: ml-100k/u1.test         \n","  inflating: ml-100k/u2.base         \n","  inflating: ml-100k/u2.test         \n","  inflating: ml-100k/u3.base         \n","  inflating: ml-100k/u3.test         \n","  inflating: ml-100k/u4.base         \n","  inflating: ml-100k/u4.test         \n","  inflating: ml-100k/u5.base         \n","  inflating: ml-100k/u5.test         \n","  inflating: ml-100k/ua.base         \n","  inflating: ml-100k/ua.test         \n","  inflating: ml-100k/ub.base         \n","  inflating: ml-100k/ub.test         \n","ml-100k  ml-100k.zip  sample_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9Xis6ldDfTs6"},"source":["###ML-1M"]},{"cell_type":"code","metadata":{"id":"LOly1yfAfTjd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630162108832,"user_tz":-300,"elapsed":1007,"user":{"displayName":"CALEB KWASI DARKO","photoUrl":"","userId":"02161131878812025596"}},"outputId":"9d17e6f9-09e9-470b-8fe6-6f684069b1b1"},"source":["!wget \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n","!unzip ml-1m.zip\n","!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2021-08-28 14:48:27--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n","Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n","Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5917549 (5.6M) [application/zip]\n","Saving to: ‘ml-1m.zip’\n","\n","ml-1m.zip           100%[===================>]   5.64M  33.3MB/s    in 0.2s    \n","\n","2021-08-28 14:48:27 (33.3 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n","\n","Archive:  ml-1m.zip\n","   creating: ml-1m/\n","  inflating: ml-1m/movies.dat        \n","  inflating: ml-1m/ratings.dat       \n","  inflating: ml-1m/README            \n","  inflating: ml-1m/users.dat         \n","ml-100k  ml-100k.zip  ml-1m  ml-1m.zip\tsample_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EOBJ8UCXdY0g"},"source":["##Importing the libraries"]},{"cell_type":"code","metadata":{"id":"_LvGeU1CeCtg","executionInfo":{"status":"ok","timestamp":1630162113153,"user_tz":-300,"elapsed":4324,"user":{"displayName":"CALEB KWASI DARKO","photoUrl":"","userId":"02161131878812025596"}}},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","from torch.autograd import Variable"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pM04FyMudkoK"},"source":["## Importing the dataset\n"]},{"cell_type":"code","metadata":{"id":"UJw2p3-Cewo4","executionInfo":{"status":"ok","timestamp":1630162125902,"user_tz":-300,"elapsed":12475,"user":{"displayName":"CALEB KWASI DARKO","photoUrl":"","userId":"02161131878812025596"}}},"source":["# We won't be using this dataset.\n","movies = pd.read_csv(\"ml-1m/movies.dat\", sep=\"::\", header=None, engine=\"python\", encoding=\"latin-1\")\n","#columns: id_movies, movie_names, movie_genre\n","users = pd.read_csv(\"ml-1m/users.dat\", sep=\"::\", header=None, engine=\"python\", encoding=\"latin-1\")\n","#users column: id_user, gender, age, job code\n","ratings = pd.read_csv(\"ml-1m/ratings.dat\", sep=\"::\", header=None, engine=\"python\", encoding=\"latin-1\")\n","#ratings column: id_user, id_movie, ratings, timestamps"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTIbE2tkdkwP"},"source":["## Preparing the training set and the test set\n"]},{"cell_type":"code","metadata":{"id":"2usLKJBEgPE2","executionInfo":{"status":"ok","timestamp":1630162125904,"user_tz":-300,"elapsed":12,"user":{"displayName":"CALEB KWASI DARKO","photoUrl":"","userId":"02161131878812025596"}}},"source":["# preparing the training and the test datasets\n","training_set = pd.read_csv(\"ml-100k/u1.base\", delimiter=\"\\t\",) #contains user, id_movie, rating, and timestamp\n","training_set = np.array(training_set, dtype=\"int\") #torch accepts numpy arrays\n","test_set = pd.read_csv(\"ml-100k/u1.base\", delimiter=\"\\t\",) #contains user, id_movie, rating, and timestamp\n","test_set = np.array(test_set, dtype=\"int\") #torch accepts numpy arrays"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zCf8HjSydk4s"},"source":["## Getting the number of users and movies\n"]},{"cell_type":"code","metadata":{"id":"gPaGZqdniC5m","executionInfo":{"status":"ok","timestamp":1630162125905,"user_tz":-300,"elapsed":11,"user":{"displayName":"CALEB KWASI DARKO","photoUrl":"","userId":"02161131878812025596"}}},"source":["#maximum number of users and movies\n","nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n","nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J-w4-hVidlAm"},"source":["## Converting the data into an array with users in lines and movies in columns\n"]},{"cell_type":"code","metadata":{"id":"-wASs2YFiDaa","executionInfo":{"status":"ok","timestamp":1630162126292,"user_tz":-300,"elapsed":398,"user":{"displayName":"CALEB KWASI DARKO","photoUrl":"","userId":"02161131878812025596"}}},"source":["# converting the training and test data into an array with users in rows, movies in columns and ratings in cells\n","# needed for pytorch, create a list of lists\n","def convert(data):\n","    new_data=[]\n","    for id_users in range(1, nb_users+1):\n","        id_movies = data[:, 1] [data[: ,0] == id_users]\n","        id_ratings = data[:,2][data[:,0]==id_users]\n","        ratings = np.zeros(nb_movies)\n","        ratings[id_movies-1]=id_ratings #movies not rated are filled with zero\n","        new_data.append(list(ratings))\n","    return new_data\n","\n","training_set = convert(training_set)\n","test_set = convert(test_set)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AMmhuUpldlHo"},"source":["## Converting the data into Torch tensors\n"]},{"cell_type":"code","metadata":{"id":"TwD-KD8yiEEw","executionInfo":{"status":"ok","timestamp":1630162126575,"user_tz":-300,"elapsed":285,"user":{"displayName":"CALEB KWASI DARKO","photoUrl":"","userId":"02161131878812025596"}}},"source":["#needed for ML and DL, better to build tensor arrays (more efficient that numpy arrays)\n","#FloatTensor expects a list of lists\n","training_set = torch.FloatTensor(training_set)\n","test_set = torch.FloatTensor(test_set)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6kkL8NkkdlZj"},"source":["## Creating the architecture of the Neural Network\n"]},{"cell_type":"code","metadata":{"id":"oU2nyh76iE6M","executionInfo":{"status":"ok","timestamp":1630162126576,"user_tz":-300,"elapsed":6,"user":{"displayName":"CALEB KWASI DARKO","photoUrl":"","userId":"02161131878812025596"}}},"source":["#we will be inheriting our functions and variables for the SAE from nn.Module (parent)\n","class SAE(nn.Module):\n","    def __init__(self, ):\n","        super(SAE, self).__init__()\n","        self.fc1 = nn.Linear(nb_movies, 20)   #20 tunable\n","        self.fc2 = nn.Linear(20, 10)\n","        self.fc3 = nn.Linear(10, 20)\n","        self.fc4 = nn.Linear(20, nb_movies)\n","        self.activation = nn.Sigmoid()\n","#building an AE with 4 layers: 2 for encoding and 2 for decoding\n","#specifying the activation function\n","\n","#encoding, decoding, and applying activation function\n","    def forward(self, x):\n","        x = self.activation(self.fc1(x))\n","        x = self.activation(self.fc2(x))\n","        x = self.activation(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","#creating an object of our SAE class\n","sae = SAE()\n","criterion = nn.MSELoss()  #a criterion for training (Mean Squared Error)\n","optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5) #lr, wd = tunable\n","#using RMS rather than Adam\n","#weight_decay=used to reduce the learning rate after every few epochs in order to regulate the convergenc"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7gy59alAdloL"},"source":["## Training the SAE\n"]},{"cell_type":"code","metadata":{"id":"FEz9hRaciFTs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630162448321,"user_tz":-300,"elapsed":321750,"user":{"displayName":"CALEB KWASI DARKO","photoUrl":"","userId":"02161131878812025596"}},"outputId":"55f13fb5-935d-4a7c-ef9b-8f0cbd7b409c"},"source":["nb_epoch = 200  #tunable\n","#building two //for loops//, one for all epochs, the other for all observations(users)\n","for epoch in range(1, nb_epoch + 1):\n","  train_loss = 0\n","  s = 0.\n","  for id_user in range(nb_users):\n","    input = Variable(training_set[id_user]).unsqueeze(0)\n","#above: creating a single input vector for online learning\n","#targets = a clone of the input\n","    target = input.clone()\n","    if torch.sum(target.data > 0) > 0:\n","      output = sae(input)\n","      target.require_grad = False #makes sure we don't compute gradient with respect to target\n","      output[target == 0] = 0 #dealing with non-zero values only\n","      loss = criterion(output, target)\n","      mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)  #for non-nil value\n","#mean_corrector represents the avverage of the error bbut by only considering the movies that were\n","#rated (non-zero ratings)\n","      loss.backward() #calling backward method for the loss\n","#backward decides the direction of weight update(increase or decrease) \n","      train_loss += np.sqrt(loss.data*mean_corrector)\n","      s += 1.\n","      optimizer.step() #optimizer decides the intensity of the update\n","  print('epoch: '+str(epoch)+'loss: '+ str(train_loss/s))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["epoch: 1loss: tensor(1.7718)\n","epoch: 2loss: tensor(1.0966)\n","epoch: 3loss: tensor(1.0534)\n","epoch: 4loss: tensor(1.0383)\n","epoch: 5loss: tensor(1.0306)\n","epoch: 6loss: tensor(1.0269)\n","epoch: 7loss: tensor(1.0239)\n","epoch: 8loss: tensor(1.0219)\n","epoch: 9loss: tensor(1.0210)\n","epoch: 10loss: tensor(1.0200)\n","epoch: 11loss: tensor(1.0191)\n","epoch: 12loss: tensor(1.0185)\n","epoch: 13loss: tensor(1.0178)\n","epoch: 14loss: tensor(1.0176)\n","epoch: 15loss: tensor(1.0174)\n","epoch: 16loss: tensor(1.0169)\n","epoch: 17loss: tensor(1.0168)\n","epoch: 18loss: tensor(1.0164)\n","epoch: 19loss: tensor(1.0164)\n","epoch: 20loss: tensor(1.0161)\n","epoch: 21loss: tensor(1.0158)\n","epoch: 22loss: tensor(1.0159)\n","epoch: 23loss: tensor(1.0158)\n","epoch: 24loss: tensor(1.0155)\n","epoch: 25loss: tensor(1.0155)\n","epoch: 26loss: tensor(1.0156)\n","epoch: 27loss: tensor(1.0153)\n","epoch: 28loss: tensor(1.0151)\n","epoch: 29loss: tensor(1.0128)\n","epoch: 30loss: tensor(1.0111)\n","epoch: 31loss: tensor(1.0103)\n","epoch: 32loss: tensor(1.0079)\n","epoch: 33loss: tensor(1.0080)\n","epoch: 34loss: tensor(1.0039)\n","epoch: 35loss: tensor(1.0040)\n","epoch: 36loss: tensor(1.0001)\n","epoch: 37loss: tensor(0.9991)\n","epoch: 38loss: tensor(0.9971)\n","epoch: 39loss: tensor(0.9962)\n","epoch: 40loss: tensor(0.9916)\n","epoch: 41loss: tensor(0.9913)\n","epoch: 42loss: tensor(0.9872)\n","epoch: 43loss: tensor(0.9876)\n","epoch: 44loss: tensor(0.9837)\n","epoch: 45loss: tensor(0.9867)\n","epoch: 46loss: tensor(0.9848)\n","epoch: 47loss: tensor(0.9877)\n","epoch: 48loss: tensor(0.9887)\n","epoch: 49loss: tensor(0.9855)\n","epoch: 50loss: tensor(0.9834)\n","epoch: 51loss: tensor(0.9803)\n","epoch: 52loss: tensor(0.9774)\n","epoch: 53loss: tensor(0.9753)\n","epoch: 54loss: tensor(0.9768)\n","epoch: 55loss: tensor(0.9840)\n","epoch: 56loss: tensor(0.9788)\n","epoch: 57loss: tensor(0.9793)\n","epoch: 58loss: tensor(0.9725)\n","epoch: 59loss: tensor(0.9775)\n","epoch: 60loss: tensor(0.9746)\n","epoch: 61loss: tensor(0.9708)\n","epoch: 62loss: tensor(0.9693)\n","epoch: 63loss: tensor(0.9700)\n","epoch: 64loss: tensor(0.9670)\n","epoch: 65loss: tensor(0.9712)\n","epoch: 66loss: tensor(0.9684)\n","epoch: 67loss: tensor(0.9692)\n","epoch: 68loss: tensor(0.9675)\n","epoch: 69loss: tensor(0.9664)\n","epoch: 70loss: tensor(0.9623)\n","epoch: 71loss: tensor(0.9598)\n","epoch: 72loss: tensor(0.9581)\n","epoch: 73loss: tensor(0.9604)\n","epoch: 74loss: tensor(0.9569)\n","epoch: 75loss: tensor(0.9565)\n","epoch: 76loss: tensor(0.9533)\n","epoch: 77loss: tensor(0.9526)\n","epoch: 78loss: tensor(0.9507)\n","epoch: 79loss: tensor(0.9502)\n","epoch: 80loss: tensor(0.9494)\n","epoch: 81loss: tensor(0.9508)\n","epoch: 82loss: tensor(0.9492)\n","epoch: 83loss: tensor(0.9477)\n","epoch: 84loss: tensor(0.9464)\n","epoch: 85loss: tensor(0.9468)\n","epoch: 86loss: tensor(0.9456)\n","epoch: 87loss: tensor(0.9441)\n","epoch: 88loss: tensor(0.9440)\n","epoch: 89loss: tensor(0.9427)\n","epoch: 90loss: tensor(0.9432)\n","epoch: 91loss: tensor(0.9422)\n","epoch: 92loss: tensor(0.9436)\n","epoch: 93loss: tensor(0.9416)\n","epoch: 94loss: tensor(0.9403)\n","epoch: 95loss: tensor(0.9391)\n","epoch: 96loss: tensor(0.9403)\n","epoch: 97loss: tensor(0.9386)\n","epoch: 98loss: tensor(0.9389)\n","epoch: 99loss: tensor(0.9384)\n","epoch: 100loss: tensor(0.9390)\n","epoch: 101loss: tensor(0.9389)\n","epoch: 102loss: tensor(0.9381)\n","epoch: 103loss: tensor(0.9371)\n","epoch: 104loss: tensor(0.9368)\n","epoch: 105loss: tensor(0.9358)\n","epoch: 106loss: tensor(0.9365)\n","epoch: 107loss: tensor(0.9359)\n","epoch: 108loss: tensor(0.9356)\n","epoch: 109loss: tensor(0.9348)\n","epoch: 110loss: tensor(0.9349)\n","epoch: 111loss: tensor(0.9345)\n","epoch: 112loss: tensor(0.9347)\n","epoch: 113loss: tensor(0.9341)\n","epoch: 114loss: tensor(0.9342)\n","epoch: 115loss: tensor(0.9338)\n","epoch: 116loss: tensor(0.9340)\n","epoch: 117loss: tensor(0.9335)\n","epoch: 118loss: tensor(0.9332)\n","epoch: 119loss: tensor(0.9328)\n","epoch: 120loss: tensor(0.9329)\n","epoch: 121loss: tensor(0.9321)\n","epoch: 122loss: tensor(0.9318)\n","epoch: 123loss: tensor(0.9321)\n","epoch: 124loss: tensor(0.9320)\n","epoch: 125loss: tensor(0.9319)\n","epoch: 126loss: tensor(0.9311)\n","epoch: 127loss: tensor(0.9305)\n","epoch: 128loss: tensor(0.9313)\n","epoch: 129loss: tensor(0.9309)\n","epoch: 130loss: tensor(0.9301)\n","epoch: 131loss: tensor(0.9297)\n","epoch: 132loss: tensor(0.9290)\n","epoch: 133loss: tensor(0.9289)\n","epoch: 134loss: tensor(0.9289)\n","epoch: 135loss: tensor(0.9279)\n","epoch: 136loss: tensor(0.9275)\n","epoch: 137loss: tensor(0.9276)\n","epoch: 138loss: tensor(0.9270)\n","epoch: 139loss: tensor(0.9275)\n","epoch: 140loss: tensor(0.9270)\n","epoch: 141loss: tensor(0.9272)\n","epoch: 142loss: tensor(0.9270)\n","epoch: 143loss: tensor(0.9268)\n","epoch: 144loss: tensor(0.9262)\n","epoch: 145loss: tensor(0.9265)\n","epoch: 146loss: tensor(0.9258)\n","epoch: 147loss: tensor(0.9257)\n","epoch: 148loss: tensor(0.9256)\n","epoch: 149loss: tensor(0.9251)\n","epoch: 150loss: tensor(0.9249)\n","epoch: 151loss: tensor(0.9249)\n","epoch: 152loss: tensor(0.9241)\n","epoch: 153loss: tensor(0.9237)\n","epoch: 154loss: tensor(0.9239)\n","epoch: 155loss: tensor(0.9247)\n","epoch: 156loss: tensor(0.9233)\n","epoch: 157loss: tensor(0.9233)\n","epoch: 158loss: tensor(0.9224)\n","epoch: 159loss: tensor(0.9233)\n","epoch: 160loss: tensor(0.9228)\n","epoch: 161loss: tensor(0.9234)\n","epoch: 162loss: tensor(0.9221)\n","epoch: 163loss: tensor(0.9224)\n","epoch: 164loss: tensor(0.9217)\n","epoch: 165loss: tensor(0.9220)\n","epoch: 166loss: tensor(0.9220)\n","epoch: 167loss: tensor(0.9213)\n","epoch: 168loss: tensor(0.9212)\n","epoch: 169loss: tensor(0.9207)\n","epoch: 170loss: tensor(0.9206)\n","epoch: 171loss: tensor(0.9207)\n","epoch: 172loss: tensor(0.9206)\n","epoch: 173loss: tensor(0.9206)\n","epoch: 174loss: tensor(0.9197)\n","epoch: 175loss: tensor(0.9206)\n","epoch: 176loss: tensor(0.9201)\n","epoch: 177loss: tensor(0.9202)\n","epoch: 178loss: tensor(0.9197)\n","epoch: 179loss: tensor(0.9188)\n","epoch: 180loss: tensor(0.9192)\n","epoch: 181loss: tensor(0.9187)\n","epoch: 182loss: tensor(0.9185)\n","epoch: 183loss: tensor(0.9192)\n","epoch: 184loss: tensor(0.9186)\n","epoch: 185loss: tensor(0.9190)\n","epoch: 186loss: tensor(0.9183)\n","epoch: 187loss: tensor(0.9184)\n","epoch: 188loss: tensor(0.9183)\n","epoch: 189loss: tensor(0.9178)\n","epoch: 190loss: tensor(0.9182)\n","epoch: 191loss: tensor(0.9181)\n","epoch: 192loss: tensor(0.9175)\n","epoch: 193loss: tensor(0.9172)\n","epoch: 194loss: tensor(0.9175)\n","epoch: 195loss: tensor(0.9182)\n","epoch: 196loss: tensor(0.9177)\n","epoch: 197loss: tensor(0.9177)\n","epoch: 198loss: tensor(0.9173)\n","epoch: 199loss: tensor(0.9176)\n","epoch: 200loss: tensor(0.9172)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Bak5uc8gd-gX"},"source":["## Testing the SAE\n"]},{"cell_type":"code","metadata":{"id":"5ztvzYRtiGCz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630162448749,"user_tz":-300,"elapsed":434,"user":{"displayName":"CALEB KWASI DARKO","photoUrl":"","userId":"02161131878812025596"}},"outputId":"9abb9015-d07e-457b-f92d-a8e6be149be0"},"source":["test_loss = 0\n","s = 0.\n","for id_user in range(nb_users):\n","  input = Variable(training_set[id_user]).unsqueeze(0)\n","  target = Variable(test_set[id_user]).unsqueeze(0)\n","  if torch.sum(target.data > 0) > 0:\n","    output = sae(input)\n","    target.require_grad = False\n","    output[target == 0] = 0\n","    loss = criterion(output, target)\n","    mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n","    test_loss += np.sqrt(loss.data*mean_corrector)\n","    s += 1.\n","print('test loss: '+str(test_loss/s))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["test loss: tensor(0.9139)\n"],"name":"stdout"}]}]}